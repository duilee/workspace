### List of research papers and helpful resources

- An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale [link](https://arxiv.org/abs/2010.11929)
  * Illustrated Transformer by Jay Alammar [link](http://jalammar.github.io/illustrated-transformer/)
  * Illustrated BERT, ELMo and more [link](http://jalammar.github.io/illustrated-bert/)
  * review of the paper [link](https://www.youtube.com/watch?v=D72_Cn-XV1g)
  
- Learning to Cartoonize Using White-box Representations [link](https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Learning_to_Cartoonize_Using_White-Box_Cartoon_Representations_CVPR_2020_paper.pdf)
  * review including guided image filter, bilateral filter. [link](https://www.notion.so/Learning-to-Cartoonize-Using-White-box-Representations-5939f22ab448453594ff01d4d33cc944)
  
- Better Language Models and Their Implications [link](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)  
  GPT-3: Language Models and Few-Shot Learners [link](https://arxiv.org/pdf/2005.14165.pdf)  
  * Illustrated GPT-2 by Jay Alammar [link](http://jalammar.github.io/illustrated-gpt2/)
  * Illustrated GPT-3 by Jay Alammar [link](http://jalammar.github.io/how-gpt3-works-visualizations-animations/)
  
- The Lottery Ticket Hypothesis: FINDING SPARSE, TRAINABLE NEURAL NETWORKS
  * Review on the paper +  Learning both Weights and Connections for Efficient Neural Networks [link](https://seing.tistory.com/47)
  * Youtube review [link](https://www.youtube.com/watch?v=dkNmYu610r8)

- Graph Attention Networks
  * Reveiw video on Youtube [link](https://www.youtube.com/watch?v=NSjpECvEf0Y)
  * blog post on towardsdatascience [link](https://towardsdatascience.com/an-introduction-to-graph-neural-network-gnn-for-analysing-structured-data-afce79f4cfdc)

- Bert4Rec 
  * blog post [link](https://22-22.tistory.com/78)
  * TL;DR used bert model to make recommendations
